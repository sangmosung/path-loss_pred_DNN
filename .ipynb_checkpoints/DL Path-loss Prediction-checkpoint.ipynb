{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1c6feb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 7) (800, 1)\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 12)                96        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 109\n",
      "Trainable params: 109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 800 samples\n",
      "Epoch 1/300\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 2482.1348 - mae: 36.3088 - acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 68.1180 - mae: 6.6592 - acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.1304 - mae: 6.5184 - acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.3926 - mae: 6.5454 - acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.4252 - mae: 6.5537 - acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.3179 - mae: 6.5311 - acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.3425 - mae: 6.5516 - acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.3117 - mae: 6.5374 - acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.1318 - mae: 6.5544 - acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.1549 - mae: 6.5162 - acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.2898 - mae: 6.5288 - acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.3289 - mae: 6.5492 - acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2054 - mae: 6.5241 - acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2186 - mae: 6.5456 - acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.2458 - mae: 6.5244 - acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "800/800 [==============================] - 0s 41us/sample - loss: 67.3261 - mae: 6.5452 - acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.1717 - mae: 6.5125 - acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "800/800 [==============================] - 0s 44us/sample - loss: 67.2894 - mae: 6.5724 - acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.2046 - mae: 6.5144 - acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.5369 - mae: 6.5658 - acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "800/800 [==============================] - 0s 40us/sample - loss: 67.2392 - mae: 6.5648 - acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "800/800 [==============================] - 0s 42us/sample - loss: 66.9879 - mae: 6.4688 - acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 67.1549 - mae: 6.5629 - acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2145 - mae: 6.5252 - acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 67.6601 - mae: 6.5478 - acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "800/800 [==============================] - 0s 39us/sample - loss: 67.1677 - mae: 6.4953 - acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.4212 - mae: 6.5541 - acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.1837 - mae: 6.5045 - acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2555 - mae: 6.5753 - acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.1354 - mae: 6.5317 - acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.2074 - mae: 6.5376 - acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.3010 - mae: 6.5331 - acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2580 - mae: 6.5130 - acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2755 - mae: 6.5381 - acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.4209 - mae: 6.5565 - acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.3749 - mae: 6.5304 - acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.0664 - mae: 6.5090 - acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2922 - mae: 6.5675 - acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.2792 - mae: 6.5465 - acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.2626 - mae: 6.5464 - acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.3112 - mae: 6.5295 - acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.2228 - mae: 6.5448 - acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.1591 - mae: 6.4910 - acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.1718 - mae: 6.5467 - acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2739 - mae: 6.5536 - acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.2034 - mae: 6.5391 - acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.3874 - mae: 6.5228 - acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.1288 - mae: 6.5308 - acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.3881 - mae: 6.5323 - acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.2309 - mae: 6.5622 - acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 67.2397 - mae: 6.5396 - acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.2757 - mae: 6.5084 - acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.4207 - mae: 6.5601 - acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.1769 - mae: 6.5402 - acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.1890 - mae: 6.5492 - acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.2841 - mae: 6.5207 - acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.2810 - mae: 6.5489 - acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 67.3469 - mae: 6.5511 - acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "800/800 [==============================] - 0s 40us/sample - loss: 67.3448 - mae: 6.5406 - acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.2327 - mae: 6.5241 - acc: 0.0000e+00\n",
      "Epoch 61/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 33us/sample - loss: 67.1391 - mae: 6.5044 - acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.1478 - mae: 6.5633 - acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.1934 - mae: 6.5331 - acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.1329 - mae: 6.5434 - acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2426 - mae: 6.5062 - acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.4634 - mae: 6.5679 - acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.1167 - mae: 6.5512 - acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.4297 - mae: 6.5085 - acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2037 - mae: 6.5250 - acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.2493 - mae: 6.5344 - acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "800/800 [==============================] - 0s 40us/sample - loss: 67.1765 - mae: 6.5374 - acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.2885 - mae: 6.5231 - acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2260 - mae: 6.5617 - acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2073 - mae: 6.5527 - acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.2245 - mae: 6.5019 - acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.2796 - mae: 6.5508 - acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.3991 - mae: 6.5455 - acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.2057 - mae: 6.5446 - acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2266 - mae: 6.5468 - acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.1986 - mae: 6.4994 - acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.1921 - mae: 6.5428 - acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2341 - mae: 6.5478 - acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "800/800 [==============================] - 0s 40us/sample - loss: 67.2603 - mae: 6.5368 - acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.1483 - mae: 6.5204 - acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2369 - mae: 6.5506 - acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 67.3980 - mae: 6.5400 - acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.1386 - mae: 6.4901 - acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 67.3703 - mae: 6.5669 - acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "800/800 [==============================] - 0s 41us/sample - loss: 67.2397 - mae: 6.5403 - acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2902 - mae: 6.5015 - acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.1593 - mae: 6.5468 - acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2492 - mae: 6.5499 - acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2909 - mae: 6.5099 - acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.4321 - mae: 6.5669 - acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.2399 - mae: 6.5438 - acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 67.3099 - mae: 6.5335 - acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.2287 - mae: 6.5485 - acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.1609 - mae: 6.5273 - acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.1972 - mae: 6.4949 - acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.1589 - mae: 6.5513 - acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "800/800 [==============================] - 0s 39us/sample - loss: 67.2778 - mae: 6.5426 - acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2175 - mae: 6.5297 - acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.1134 - mae: 6.5580 - acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.3650 - mae: 6.5238 - acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.3084 - mae: 6.5349 - acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.3126 - mae: 6.5452 - acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.3471 - mae: 6.5516 - acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2018 - mae: 6.5243 - acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.3525 - mae: 6.5464 - acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.1433 - mae: 6.5582 - acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.3419 - mae: 6.5185 - acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.1295 - mae: 6.4977 - acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.2605 - mae: 6.5793 - acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.3865 - mae: 6.5324 - acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.2524 - mae: 6.5309 - acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.1236 - mae: 6.5256 - acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 67.4745 - mae: 6.5563 - acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2552 - mae: 6.5311 - acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.3026 - mae: 6.5329 - acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2580 - mae: 6.5576 - acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 66.9951 - mae: 6.4886 - acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.1996 - mae: 6.5194 - acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "800/800 [==============================] - 0s 40us/sample - loss: 67.1226 - mae: 6.5632 - acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.1091 - mae: 6.4872 - acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.6131 - mae: 6.5740 - acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "800/800 [==============================] - 0s 39us/sample - loss: 67.1460 - mae: 6.5476 - acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 67.4530 - mae: 6.5304 - acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.3633 - mae: 6.5229 - acc: 0.0000e+00\n",
      "Epoch 129/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2751 - mae: 6.5479 - acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2817 - mae: 6.5201 - acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.2362 - mae: 6.5301 - acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2714 - mae: 6.5312 - acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2826 - mae: 6.5432 - acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.2872 - mae: 6.5533 - acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.3273 - mae: 6.5544 - acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.3156 - mae: 6.5239 - acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "800/800 [==============================] - 0s 40us/sample - loss: 67.2638 - mae: 6.5331 - acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "800/800 [==============================] - 0s 43us/sample - loss: 67.1840 - mae: 6.4967 - acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.4447 - mae: 6.5516 - acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.3388 - mae: 6.5822 - acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 67.3389 - mae: 6.5213 - acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.5089 - mae: 6.5465 - acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "800/800 [==============================] - 0s 41us/sample - loss: 67.1300 - mae: 6.5047 - acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.1994 - mae: 6.5698 - acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "800/800 [==============================] - 0s 43us/sample - loss: 67.0436 - mae: 6.5043 - acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2347 - mae: 6.5440 - acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 67.2654 - mae: 6.5384 - acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 67.2237 - mae: 6.5340 - acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.2459 - mae: 6.5424 - acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "800/800 [==============================] - 0s 41us/sample - loss: 67.1732 - mae: 6.5462 - acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 67.2943 - mae: 6.5080 - acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.4405 - mae: 6.5587 - acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.2265 - mae: 6.5450 - acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.2073 - mae: 6.5129 - acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.3110 - mae: 6.5749 - acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "800/800 [==============================] - 0s 41us/sample - loss: 67.2737 - mae: 6.5186 - acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.3139 - mae: 6.5188 - acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.5569 - mae: 6.5843 - acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2233 - mae: 6.5336 - acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.2452 - mae: 6.5150 - acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 67.1367 - mae: 6.5391 - acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.4187 - mae: 6.5259 - acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.2574 - mae: 6.5607 - acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.3407 - mae: 6.5355 - acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.3013 - mae: 6.5430 - acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.3004 - mae: 6.5367 - acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "800/800 [==============================] - 0s 42us/sample - loss: 67.2858 - mae: 6.5553 - acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.4392 - mae: 6.5317 - acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.1500 - mae: 6.5369 - acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.2530 - mae: 6.5254 - acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.3316 - mae: 6.5565 - acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.2245 - mae: 6.4980 - acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.3549 - mae: 6.5654 - acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.2921 - mae: 6.5112 - acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.1437 - mae: 6.5537 - acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.3070 - mae: 6.5414 - acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.1596 - mae: 6.5263 - acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.2969 - mae: 6.5107 - acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.5401 - mae: 6.5459 - acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.3763 - mae: 6.5425 - acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.3584 - mae: 6.5477 - acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.2626 - mae: 6.5548 - acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.2852 - mae: 6.5255 - acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.1773 - mae: 6.5133 - acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.4234 - mae: 6.5610 - acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 67.1440 - mae: 6.5132 - acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "800/800 [==============================] - 0s 28us/sample - loss: 67.2256 - mae: 6.5392 - acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.2537 - mae: 6.5162 - acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2011 - mae: 6.5769 - acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.1975 - mae: 6.5181 - acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.1713 - mae: 6.5496 - acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.2682 - mae: 6.5358 - acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.3095 - mae: 6.5312 - acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "800/800 [==============================] - 0s 39us/sample - loss: 67.2975 - mae: 6.5630 - acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "800/800 [==============================] - 0s 44us/sample - loss: 67.3450 - mae: 6.5474 - acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.2480 - mae: 6.5322 - acc: 0.0000e+00\n",
      "Epoch 197/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 36us/sample - loss: 67.2552 - mae: 6.5583 - acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.3471 - mae: 6.5102 - acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.0372 - mae: 6.5434 - acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.3108 - mae: 6.5289 - acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.0461 - mae: 6.5453 - acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2305 - mae: 6.4899 - acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.1931 - mae: 6.5188 - acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2224 - mae: 6.5377 - acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.3548 - mae: 6.5547 - acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2785 - mae: 6.5234 - acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 67.2399 - mae: 6.5436 - acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.3058 - mae: 6.5192 - acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.3496 - mae: 6.5587 - acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.1744 - mae: 6.5213 - acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.2059 - mae: 6.5427 - acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2491 - mae: 6.5370 - acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2499 - mae: 6.5392 - acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "800/800 [==============================] - 0s 39us/sample - loss: 67.2370 - mae: 6.5157 - acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 67.3883 - mae: 6.5678 - acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "800/800 [==============================] - 0s 39us/sample - loss: 67.2246 - mae: 6.5088 - acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2929 - mae: 6.5699 - acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 67.1906 - mae: 6.5127 - acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.1593 - mae: 6.5311 - acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "800/800 [==============================] - 0s 38us/sample - loss: 67.2930 - mae: 6.5507 - acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2305 - mae: 6.5362 - acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 67.2037 - mae: 6.5462 - acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 67.3503 - mae: 6.5302 - acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.1600 - mae: 6.5181 - acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.2125 - mae: 6.5523 - acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.3915 - mae: 6.5304 - acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.3421 - mae: 6.5228 - acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.2154 - mae: 6.5438 - acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "800/800 [==============================] - 0s 41us/sample - loss: 67.1129 - mae: 6.5398 - acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.1469 - mae: 6.5395 - acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.3956 - mae: 6.5326 - acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.3122 - mae: 6.5314 - acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.3520 - mae: 6.5363 - acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.4281 - mae: 6.5533 - acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.3543 - mae: 6.5399 - acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.4433 - mae: 6.5288 - acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.3019 - mae: 6.5801 - acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.1428 - mae: 6.5001 - acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.2688 - mae: 6.5188 - acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.3075 - mae: 6.5716 - acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2433 - mae: 6.5598 - acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2478 - mae: 6.5001 - acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.4365 - mae: 6.5755 - acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.1873 - mae: 6.5307 - acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.1288 - mae: 6.5022 - acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.4533 - mae: 6.5564 - acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "800/800 [==============================] - 0s 28us/sample - loss: 67.2518 - mae: 6.5413 - acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.3605 - mae: 6.5555 - acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.3620 - mae: 6.5328 - acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.3575 - mae: 6.5298 - acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.3124 - mae: 6.5247 - acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.2098 - mae: 6.5583 - acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.3184 - mae: 6.5280 - acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.0752 - mae: 6.5425 - acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.1676 - mae: 6.4783 - acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2516 - mae: 6.5715 - acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.2658 - mae: 6.5345 - acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "800/800 [==============================] - 0s 39us/sample - loss: 67.2610 - mae: 6.5442 - acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2910 - mae: 6.5394 - acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.0528 - mae: 6.5228 - acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.3357 - mae: 6.5383 - acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2328 - mae: 6.5386 - acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.3180 - mae: 6.5572 - acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.3477 - mae: 6.5432 - acc: 0.0000e+00\n",
      "Epoch 265/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 32us/sample - loss: 67.3681 - mae: 6.5287 - acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.3158 - mae: 6.5466 - acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2713 - mae: 6.5232 - acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "800/800 [==============================] - 0s 29us/sample - loss: 67.2433 - mae: 6.5379 - acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "800/800 [==============================] - 0s 35us/sample - loss: 67.0086 - mae: 6.4798 - acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2840 - mae: 6.5654 - acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.0954 - mae: 6.5027 - acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.1670 - mae: 6.5535 - acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2794 - mae: 6.5334 - acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.4086 - mae: 6.5245 - acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.3457 - mae: 6.5612 - acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2230 - mae: 6.5366 - acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.2317 - mae: 6.5133 - acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2153 - mae: 6.5217 - acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2602 - mae: 6.5498 - acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.4503 - mae: 6.5529 - acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.2942 - mae: 6.5393 - acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "800/800 [==============================] - 0s 30us/sample - loss: 67.3613 - mae: 6.5251 - acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2553 - mae: 6.5355 - acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.4177 - mae: 6.5431 - acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.1714 - mae: 6.5230 - acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.3910 - mae: 6.5752 - acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "800/800 [==============================] - 0s 28us/sample - loss: 67.3067 - mae: 6.5495 - acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.4828 - mae: 6.5412 - acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2730 - mae: 6.5469 - acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.1940 - mae: 6.5188 - acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "800/800 [==============================] - 0s 39us/sample - loss: 67.2048 - mae: 6.5186 - acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "800/800 [==============================] - 0s 37us/sample - loss: 67.2712 - mae: 6.5491 - acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.2520 - mae: 6.5473 - acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.3147 - mae: 6.5361 - acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "800/800 [==============================] - 0s 31us/sample - loss: 67.0281 - mae: 6.5480 - acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "800/800 [==============================] - 0s 36us/sample - loss: 67.2728 - mae: 6.5395 - acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2970 - mae: 6.5337 - acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "800/800 [==============================] - 0s 32us/sample - loss: 67.2612 - mae: 6.5343 - acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "800/800 [==============================] - 0s 33us/sample - loss: 67.2106 - mae: 6.5418 - acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "800/800 [==============================] - 0s 34us/sample - loss: 67.6165 - mae: 6.5566 - acc: 0.0000e+00\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "[[122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]\n",
      " [122.840904]]\n",
      "    Pathloss\n",
      "0    133.980\n",
      "1    136.677\n",
      "2    128.739\n",
      "3    134.745\n",
      "4    134.735\n",
      "..       ...\n",
      "95   127.573\n",
      "96   127.561\n",
      "97   127.548\n",
      "98   127.536\n",
      "99   127.523\n",
      "\n",
      "[100 rows x 1 columns]\n",
      "[array([[ 2.01765180e-01, -6.22820556e-02, -4.96715307e-03,\n",
      "         6.77143872e-01, -6.07953370e-02, -2.66870469e-01,\n",
      "        -1.10391891e+00,  4.58638847e-01, -2.96225011e-01,\n",
      "         2.13372111e-02,  8.31337720e-02,  2.80803299e+00],\n",
      "       [-3.47581327e-01,  4.97197568e-01, -3.47331166e-01,\n",
      "         3.18038988e+00, -9.08725679e-01, -3.92859071e-01,\n",
      "        -8.25687587e-01,  5.46735227e-01,  5.46065450e-01,\n",
      "         1.30145848e-01,  1.25493437e-01,  3.02525020e+00],\n",
      "       [-6.08814359e-02,  4.06370759e-01, -4.01178122e-01,\n",
      "         6.47659826e+00, -1.52462578e+00, -7.73316622e-03,\n",
      "        -1.88156343e+00, -2.34130412e-01,  1.81384885e+00,\n",
      "         2.37532556e-01, -1.06895916e-01,  5.86413145e+00],\n",
      "       [-5.55300295e-01,  4.51053083e-01,  2.30504811e-01,\n",
      "        -2.39651322e-01, -2.39353746e-01,  3.26613784e-01,\n",
      "         4.45237160e-02, -5.37858009e-01,  5.04844129e-01,\n",
      "         5.07383168e-01, -4.77747381e-01,  4.57522869e-02],\n",
      "       [-5.42280853e-01,  3.57580900e-01, -5.22434711e-01,\n",
      "         3.50243797e+01, -2.71537876e+00, -1.65101796e-01,\n",
      "        -9.69831753e+00,  2.99064338e-01,  1.41588106e+01,\n",
      "         2.61626244e-02, -4.20008272e-01,  2.41529942e+00],\n",
      "       [ 3.76475215e-01, -5.32532990e-01,  3.81044745e-02,\n",
      "         1.26775503e-02, -3.54878902e-02,  6.47026300e-03,\n",
      "        -3.04193616e-01, -4.19477761e-01, -3.09119105e-01,\n",
      "         3.39087248e-01,  4.11351204e-01,  2.90911019e-01],\n",
      "       [-2.14402318e-01, -1.23112798e-02, -1.06711596e-01,\n",
      "         9.38200206e-02,  5.23213267e-01, -4.56616282e-02,\n",
      "        -1.69516578e-01,  4.42702234e-01,  5.27838409e-01,\n",
      "        -3.78585815e-01,  1.53113350e-01,  3.36966008e-01]], dtype=float32), array([ 0.        ,  0.        ,  0.        ,  0.05160891, -0.00834351,\n",
      "        0.        , -0.01790155,  0.        ,  0.01328516,  0.        ,\n",
      "       -0.00036277,  0.0594515 ], dtype=float32), array([[ 0.36945546],\n",
      "       [17.49101   ],\n",
      "       [-0.3751691 ],\n",
      "       [16.445719  ],\n",
      "       [ 1.2450175 ],\n",
      "       [ 0.37029886],\n",
      "       [ 0.3454914 ],\n",
      "       [17.998049  ],\n",
      "       [16.248056  ],\n",
      "       [18.643229  ],\n",
      "       [ 0.39553648],\n",
      "       [17.923666  ]], dtype=float32), array([18.09118], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# 라이브러리 사용\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    " \n",
    "###########################\n",
    "# 1.과거의 데이터를 준비합니다.\n",
    "보스턴 = pd.read_csv(\"/home/smsung/Downloads/MilliCar-SUMO/Test/Test_data_220120/cv_s60_i0.0_k0.0_a0.0_l_S_Highway.txt\",sep='\\t', names=['seq','speed','IR','Pathloss','dist','WA','WC','SC'])\n",
    " \n",
    "# 종속변수, 독립변수\n",
    "독립 = 보스턴[['seq','speed','IR','dist','WA','WC']]\n",
    "종속 = 보스턴[['Pathloss']]\n",
    "print(독립.shape, 종속.shape)\n",
    " \n",
    "###########################\n",
    "# 2. 모델의 구조를 만듭니다\n",
    "X = tf.keras.layers.Input(shape=[6])\n",
    "H = tf.keras.layers.Dense(32, activation='tanh')(X)\n",
    "H = tf.keras.layers.Dense(64, activation='tanh')(X)\n",
    "H = tf.keras.layers.Dense(32, activation='tanh')(X)\n",
    "H = tf.keras.layers.Dense(12, activation='sigmoid')(X)\n",
    "Y = tf.keras.layers.Dense(1)(H)\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=['mae', 'acc'])\n",
    " \n",
    "# 모델 구조 확인\n",
    "model.summary()\n",
    " \n",
    "###########################\n",
    "# 3.데이터로 모델을 학습(FIT)합니다.\n",
    "model.fit(독립, 종속, epochs=300)\n",
    " \n",
    "###########################\n",
    "# 4. 모델을 이용합니다\n",
    "print(model.predict(독립[:100]))\n",
    "print(종속[:100])\n",
    " \n",
    "###########################\n",
    "# 모델의 수식 확인\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d06f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
